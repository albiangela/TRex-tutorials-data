{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e45ed01-7c19-4318-a669-a0334df95115",
   "metadata": {},
   "source": [
    "# Train Custom YOLO Models for Object Detection\n",
    "\n",
    "This notebook is designed to help you train your own YOLO object detection models from scratch or fine-tune existing ones.  \n",
    "You can use either:\n",
    "\n",
    "- **Local datasets** (e.g., in YOLO format stored on your Google Drive or GitHub)\n",
    "- **Datasets from Roboflow**, which can be easily imported via a download link\n",
    "\n",
    "The workflow includes:\n",
    "- Loading and organizing your dataset\n",
    "- Writing a custom `.yaml` config file\n",
    "- Launching training with the `ultralytics` YOLO implementation\n",
    "- (Optional) Exporting and evaluating your trained model\n",
    "\n",
    "This is ideal for training models on custom objects — whether you're working with animals, vehicles, tools, or underwater footage.\n",
    "\n",
    "---\n",
    "\n",
    "Make sure your dataset is in the correct YOLO structure:\n",
    "\n",
    "```\n",
    "dataset/\n",
    "├── train/\n",
    "│   ├── images/\n",
    "│   └── labels/\n",
    "├── valid/\n",
    "│   ├── images/\n",
    "│   └── labels/\n",
    "├── test/   # optional\n",
    "│   ├── images/\n",
    "│   └── labels/\n",
    "└── data.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0892d97b-d9d7-493e-8285-5770875b300d",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11d51667-95ca-4a74-badf-f3cfa9c72e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.38 🚀 Python-3.12.7 torch-2.5.1.post4 CPU (Apple M2 Pro)\n",
      "Setup complete ✅ (12 CPUs, 32.0 GB RAM, 880.9/926.4 GB disk)\n",
      "/Users/ang/Seafile/TRex-tutorials-data/code\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import math\n",
    "import glob\n",
    "from IPython.display import Image, display\n",
    "import numpy as np\n",
    "import time  # Import the time module\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "from utils import *\n",
    "\n",
    "# from google.colab import runtime\n",
    "# from google.colab import drive\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from IPython.display import display, Image\n",
    "\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e448cc-e986-4909-bda8-51225977917a",
   "metadata": {},
   "source": [
    "#### There are options: 1) to load data from local folder (.zip folder) 2) to get data directly from roboflow\n",
    "Chose the one that applies to your case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813fcf1e-a0a9-4257-ab7f-c38b74d1c376",
   "metadata": {},
   "source": [
    "# 1) Load data from local folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff2174f5-a2c8-4f16-ac19-e31f9e4ebee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: /content: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'TRex-tutorials-data'...\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# USER OPTION: Choose your data source\n",
    "# -------------------------------\n",
    "USE_LOCAL = False  # Set to True if loading from Google Drive\n",
    "\n",
    "# -------------------------------\n",
    "# Setup\n",
    "# -------------------------------\n",
    "import os\n",
    "\n",
    "# Clean and prepare dataset directory\n",
    "!rm -rf /content/datasets\n",
    "!mkdir /content/datasets\n",
    "\n",
    "if USE_LOCAL:\n",
    "    # --- Option 1: Load from Google Drive ---\n",
    "    dir_name = \"/Users/ang/Google Drive//models/hexbugs/\"\n",
    "    name = \"hexseg.v2i.yolov11\"\n",
    "\n",
    "    # Unzip the dataset\n",
    "    !unzip {dir_name}{name}.zip -d /content/datasets\n",
    "\n",
    "else:\n",
    "\n",
    "    # --- Option 2: Clone from GitHub (for local Jupyter setup) ---\n",
    "    name = \"hexbugs-annotation-dataset\"\n",
    "    repo_url = \"https://github.com/albiangela/TRex-tutorials-data.git\"\n",
    "    local_base = Path.cwd() / \"datasets\"\n",
    "    dataset_path = local_base / name\n",
    "    \n",
    "    # Ensure the datasets folder exists\n",
    "    local_base.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Clone the repository\n",
    "    os.system(f\"git clone {repo_url}\")\n",
    "    \n",
    "    # Copy the dataset folder to the local datasets directory\n",
    "    source_folder = Path(\"TRex-tutorials-data/YOLO-models\") / name\n",
    "    shutil.copytree(source_folder, dataset_path, dirs_exist_ok=True)\n",
    "    \n",
    "    # Unzip dataset (assumes only one ZIP file in the folder)\n",
    "    zip_files = list(dataset_path.glob(\"*.zip\"))\n",
    "    if zip_files:\n",
    "        with zipfile.ZipFile(zip_files[0], 'r') as zip_ref:\n",
    "            zip_ref.extractall(dataset_path)\n",
    "        zip_files[0].unlink()  # remove zip after extraction\n",
    "    \n",
    "    # Move unzipped contents up one level if nested in a subfolder\n",
    "    nested_folder = dataset_path / name\n",
    "    if nested_folder.exists() and nested_folder.is_dir():\n",
    "        for item in nested_folder.iterdir():\n",
    "            shutil.move(str(item), str(dataset_path))\n",
    "        shutil.rmtree(nested_folder)\n",
    "    \n",
    "    # Clean up cloned repo\n",
    "    shutil.rmtree(\"TRex-tutorials-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67ee34d2-46fd-4085-8058-95e91238997e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset location: /Users/ang/Seafile/TRex-tutorials-data/code/datasets/hexbugs-annotation-dataset\n"
     ]
    }
   ],
   "source": [
    "# Define a simple class to hold dataset metadata\n",
    "class Data:\n",
    "    def __init__(self, location, name, version=1):\n",
    "        self.location = Path(location).resolve()  # Convert to absolute Path object\n",
    "        self.version = version                    # Optional versioning\n",
    "        self.name = name                          # Name of the dataset\n",
    "\n",
    "# Create an instance of the Data class with the path and name of the dataset\n",
    "dataset = Data(Path(\"datasets\") / name, name)\n",
    "\n",
    "# Assert that the 'train' folder exists within the dataset location\n",
    "# This will raise an error if the folder is missing\n",
    "assert (dataset.location / \"train\").exists(), f\"'train' folder not found in {dataset.location}\"\n",
    "\n",
    "# Return or print the dataset location\n",
    "print(\"Dataset location:\", dataset.location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98405ee-3db5-46ce-b23e-d35c132098ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "prepare_yolo_dataset(\n",
    "    dataset_path=dataset.location,  # your original dataset object\n",
    "    output_path=str(output_path),   # convert Path object to string\n",
    "    split=(0.7, 0.2, 0.1),          # train, valid, test\n",
    "    remove_test=False               # keep test if it exists\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ba9e383-e5c6-44fb-a221-724daaf21022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebalanced dataset saved to: /Users/ang/Seafile/TRex-tutorials-data/code/rebalanced_dataset\n",
      "Train: 28 | valid: 8 | test: 5\n",
      "Dataset prepared successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set output path to a new folder named 'rebalanced_dataset' in the current working directory\n",
    "output_path = Path.cwd() / \"rebalanced_dataset\"\n",
    "\n",
    "prepare_yolo_dataset(\n",
    "    dataset_path=dataset.location,  # your original dataset object\n",
    "    output_path=str(output_path),   # convert Path object to string\n",
    "    split=(0.7, 0.2, 0.1),          # train, valid, test\n",
    "    remove_test=False               # keep test if it exists\n",
    ")\n",
    "\n",
    "# ## If you want to change the labels, the function will look more like this\n",
    "# prepare_yolo_dataset(\n",
    "#     dataset_path=dataset.location,  # your original dataset object\n",
    "#     output_path=str(output_path),   # convert Path object to string\n",
    "#     split=(0.7, 0.2, 0.1),\n",
    "#     remove_test=False,\n",
    "#     allowed_ids={0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10},\n",
    "#     collapse_map=collapse_map,\n",
    "#     new_class_ids=new_class_ids,\n",
    "#     drop_others=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd59677a-3800-4c46-884a-60e7d0ebb46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class counts: Counter({0: 140})\n",
      "Valid class counts: Counter({0: 40})\n",
      "Test class counts: Counter({0: 25})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def count_labels(label_dir):\n",
    "    class_counts = Counter()\n",
    "    for fname in os.listdir(label_dir):\n",
    "        if not fname.endswith('.txt'):\n",
    "            continue\n",
    "        with open(os.path.join(label_dir, fname)) as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if parts:\n",
    "                    try:\n",
    "                        class_id = int(parts[0])\n",
    "                        class_counts[class_id] += 1\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "    return class_counts\n",
    "\n",
    "# Check balance\n",
    "print(\"Train class counts:\", count_labels(Path.cwd() / 'rebalanced_dataset/train/labels'))\n",
    "print(\"Valid class counts:\", count_labels(Path.cwd() / 'rebalanced_dataset/valid/labels'))\n",
    "print(\"Test class counts:\", count_labels(Path.cwd() / 'rebalanced_dataset/test/labels'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d988123-ef30-47bb-aa7c-566b2285e683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ang/Seafile/TRex-tutorials-data/code/rebalanced_dataset')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a simple class to hold dataset metadata\n",
    "class Data:\n",
    "    def __init__(self, location, name, version=1):\n",
    "        self.location = Path(location).resolve()  # Ensure it's a full path\n",
    "        self.version = version\n",
    "        self.name = name\n",
    "\n",
    "# Try to use a named rebalanced dataset with previous name as prefix, fallback if dataset.name is not defined\n",
    "try:\n",
    "    dataset = Data(Path.cwd() / \"rebalanced_dataset\", dataset.name + \"_rebalanced\")\n",
    "except NameError:\n",
    "    print(\"⚠️ 'dataset.name' not defined. Falling back to default name 'rebalanced'.\")\n",
    "    dataset = Data(Path.cwd() / \"rebalanced_dataset\", \"rebalanced\")\n",
    "\n",
    "# Assert that the 'train' folder exists\n",
    "assert (dataset.location / \"train\").exists(), f\"'train' folder not found in: {dataset.location}\"\n",
    "\n",
    "# Show the resolved dataset path\n",
    "dataset.location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60b86079-2688-41ac-8afe-4474ab4a302d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Copied dataset config from /Users/ang/Seafile/TRex-tutorials-data/code/datasets/hexbugs-annotation-dataset/data.yaml to /Users/ang/Seafile/TRex-tutorials-data/code/rebalanced_dataset/data.yaml\n"
     ]
    }
   ],
   "source": [
    "# Define source and destination paths\n",
    "source_yaml = Path(dataset_path) / \"data.yaml\"  # or \"dataset.yaml\" if that's the actual name\n",
    "if not source_yaml.exists():\n",
    "    source_yaml = Path(dataset_path) / \"dataset.yaml\"  # fallback if using a different name\n",
    "\n",
    "destination_yaml = dataset.location / \"data.yaml\"\n",
    "\n",
    "# Copy the YAML file\n",
    "shutil.copy(source_yaml, destination_yaml)\n",
    "\n",
    "print(f\"✅ Copied dataset config from {source_yaml} to {destination_yaml}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21a5a15-562c-43cd-bd3e-f84091052ef2",
   "metadata": {},
   "source": [
    "# 4) Define Training paramenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3bf4cd3-12af-4000-975c-af88e41c8894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working in directory: /Users/ang/Seafile/TRex-tutorials-data/code\n",
      "✅ Directory '/Users/ang/Seafile/TRex-tutorials-data/code/models/rocks' created.\n"
     ]
    }
   ],
   "source": [
    "# Define your local output folder for saving models\n",
    "REMOTE_URL = Path.cwd() / \"models\" / \"rocks\"\n",
    "HOME = Path.cwd()\n",
    "\n",
    "# Change to HOME directory (optional in local Jupyter, just informative here)\n",
    "print(f\"Working in directory: {HOME}\")\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not REMOTE_URL.exists():\n",
    "    REMOTE_URL.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"✅ Directory '{REMOTE_URL}' created.\")\n",
    "else:\n",
    "    print(f\"📁 Directory '{REMOTE_URL}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ca541c8-4d42-43d6-b961-891a89f2db15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ang/Seafile/TRex-tutorials-data/code\n",
      "🔧 Training params: translate=0.25 mixup=0.001 copy_paste=0.15 scale=0.25 mosaic=1 close_mosaic=10 line_width=1 optimize=True dynamic=True format=tflite nms=True half=False plots=True cache=disk single_cls=False amp=True augment=False workers=16 degrees=0 flipud=0.0 fliplr=0.0\n",
      "🧪 resolution=1980 | project=1980-yolo11n-seg-mosaic | date_string=2025-06-10-00_hexbugs-annotation-dataset_rebalanced_rebalanced-1\n",
      "📦 model=yolo11n-seg | base_model=yolo11n-seg | task=segment\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Change to home directory\n",
    "%cd {HOME}\n",
    "\n",
    "# ---- User-defined Settings ----\n",
    "resolution = 1980                # Image resolution for training\n",
    "epochs = 100                     # Number of training epochs\n",
    "batch_size = 4                   # Batch size\n",
    "base_model = \"yolo11n-seg\"       # Choose model variant. Options: \"yolo11n-pose\", \"yolo11n-seg\", \"yolo11n\" etc.\n",
    "cropped = False                  # Whether images are cropped (affects naming only)\n",
    "# sharkcam = True                  # Used for naming (optional toggle)\n",
    "\n",
    "\n",
    "# ---- Auto-detect task type ----\n",
    "if \"-seg\" in base_model:\n",
    "    task = \"segment\"\n",
    "elif \"-pose\" in base_model:\n",
    "    task = \"pose\"\n",
    "else:\n",
    "    task = \"detect\"\n",
    "\n",
    "# ---- 🔧 Training Settings ----\n",
    "common_settings = {\n",
    "    \"translate\": 0.25,       # Maximum image translation as data augmentation (in % of image size)\n",
    "    \"mixup\": 0.001,          # MixUp blending factor for image mixing (usually low for object detection)\n",
    "    \"copy_paste\": 0.15,      # Probability of using Copy-Paste augmentation (object pasting)\n",
    "    \"scale\": 0.25,           # Random scaling of images for augmentation\n",
    "    \"mosaic\": 1,             # Enable Mosaic augmentation (combines 4 images into 1)\n",
    "    \"close_mosaic\": 10,      # Number of epochs before disabling mosaic for better fine-tuning\n",
    "    \"line_width\": 1,         # Line width for label visualization\n",
    "    \"optimize\": True,        # Apply training graph optimization\n",
    "    \"dynamic\": True,         # Dynamic input resizing (True enables better memory usage)\n",
    "    \"format\": \"tflite\",      # Export model format (e.g., 'tflite', 'onnx', 'torchscript')\n",
    "    \"nms\": True,             # Apply Non-Maximum Suppression during inference\n",
    "    \"half\": False,           # Use 16-bit (half) precision if supported\n",
    "    \"plots\": True,           # Save training plots (loss, mAP, etc.)\n",
    "    \"cache\": \"disk\",         # Caching mode: \"disk\" to speed up I/O\n",
    "    \"single_cls\": False,     # If True, treat all objects as one class (for class-agnostic detection)\n",
    "    \"amp\": True,             # Enable automatic mixed precision (reduces memory, speeds up training)\n",
    "    \"augment\": False,        # If True, applies augmentation at inference time\n",
    "    \"workers\": 16            # Number of dataloader workers (adjust depending on your CPU)\n",
    "}\n",
    "\n",
    "# Modify task-specific augmentations\n",
    "if task == \"detect\":\n",
    "    common_settings.update({\n",
    "        \"degrees\": 180,       # Allow full rotation\n",
    "        \"flipud\": 0.25,       # Vertical flip probability\n",
    "        \"fliplr\": 0.25        # Horizontal flip probability\n",
    "    })\n",
    "else:\n",
    "    common_settings.update({\n",
    "        \"degrees\": 0,         # No rotation for pose/seg\n",
    "        \"flipud\": 0.0,\n",
    "        \"fliplr\": 0.0\n",
    "    })\n",
    "\n",
    "# Print CLI training parameters\n",
    "parms = \" \".join([f\"{k}={v}\" for k, v in common_settings.items()])\n",
    "print(\"🔧 Training params:\", parms)\n",
    "\n",
    "# ---- 🗂️ Model Output Naming ----\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "date_string = now.strftime(\"%Y-%m-%d-%H\") + \"_\" + dataset.name.replace(\" \", \"-\") + \"-\" + str(dataset.version)\n",
    "\n",
    "project = f\"{resolution}-{base_model}\"\n",
    "if common_settings[\"mosaic\"] > 0:\n",
    "    project += \"-mosaic\"\n",
    "if cropped:\n",
    "    project += \"-cropped\"\n",
    "# if sharkcam:\n",
    "#     project += \"-sharkcam\"  # Add logic if needed\n",
    "\n",
    "# ---- 🧠 Model Weights Source ----\n",
    "model = base_model  # or path to a pretrained model\n",
    "print(f\"🧪 resolution={resolution} | project={project} | date_string={date_string}\")\n",
    "print(f\"📦 model={model} | base_model={base_model} | task={task}\")\n",
    "\n",
    "# ---- 🔒 Safety Check ----\n",
    "import os\n",
    "assert model == base_model or os.path.exists(model + \".pt\"), f\"Model path not found: {model}.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaebae7-54c5-4ded-b9ee-f91a99863bb7",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4846b3cc-5d79-4677-8a02-963193eb261e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ang/Seafile/TRex-tutorials-data/code\n",
      "New https://pypi.org/project/ultralytics/8.3.152 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.38 🚀 Python-3.12.7 torch-2.5.1.post4 CPU (Apple M2 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=yolo11n-seg.pt, data=/Users/ang/Seafile/TRex-tutorials-data/code/rebalanced_dataset/data.yaml, epochs=100, time=None, patience=0, batch=4, imgsz=1980, save=True, save_period=-1, cache=disk, device=cpu, workers=16, project=1980-yolo11n-seg-mosaic, name=2025-06-10-00_hexbugs-annotation-dataset_rebalanced_rebalanced-1, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=True, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=1, format=tflite, keras=False, optimize=True, int8=False, dynamic=True, simplify=True, opset=None, workspace=None, nms=True, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0, translate=0.25, scale=0.25, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, bgr=0.0, mosaic=1, mixup=0.001, copy_paste=0.15, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=1980-yolo11n-seg-mosaic/2025-06-10-00_hexbugs-annotation-dataset_rebalanced_rebalanced-1\n",
      "Unable to revert mtime: /Library/Fonts\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    683635  ultralytics.nn.modules.head.Segment          [1, 32, 64, [64, 128, 256]]   \n",
      "YOLO11n-seg summary: 355 layers, 2,842,803 parameters, 2,842,787 gradients, 10.4 GFLOPs\n",
      "\n",
      "Transferred 510/561 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir 1980-yolo11n-seg-mosaic/2025-06-10-00_hexbugs-annotation-dataset_rebalanced_rebalanced-1', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "WARNING ⚠️ imgsz=[1980] must be multiple of max stride 32, updating to [1984]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/ang/Seafile/TRex-tutorials-data/code/rebalanced_dataset/t\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/ang/Seafile/TRex-tutorials-data/code/rebalanced_dataset/train/labels.cache\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.3GB Disk): 100%|██████████| 28/28 [00:00<00:00, 245.16i\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/ang/Seafile/TRex-tutorials-data/code/rebalanced_dataset/val\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/ang/Seafile/TRex-tutorials-data/code/rebalanced_dataset/valid/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB Disk): 100%|██████████| 8/8 [00:00<00:00, 167.60it/s]\u001b[0m\n",
      "Plotting labels to 1980-yolo11n-seg-mosaic/2025-06-10-00_hexbugs-annotation-dataset_rebalanced_rebalanced-1/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 90 weight(decay=0.0), 101 weight(decay=0.0005), 100 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 1984 train, 1984 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m1980-yolo11n-seg-mosaic/2025-06-10-00_hexbugs-annotation-dataset_rebalanced_rebalanced-1\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      1/100         0G     0.6119      1.443      4.319     0.8673         30   ^C\n"
     ]
    }
   ],
   "source": [
    "# Change to your working directory\n",
    "%cd {HOME}\n",
    "\n",
    "yolo_cmd = f\"\"\"\n",
    "yolo task={task} \\\n",
    "     mode=train \\\n",
    "     resume=False \\\n",
    "     model={model}.pt \\\n",
    "     data={dataset.location}/data.yaml \\\n",
    "     device=cpu \\\n",
    "     name={date_string} \\\n",
    "     project={project} \\\n",
    "     epochs={epochs} \\\n",
    "     imgsz={resolution} \\\n",
    "     batch={batch_size} \\\n",
    "     patience=0 \\\n",
    "     visualize=True \\\n",
    "     {parms}\n",
    "\"\"\"\n",
    "\n",
    "# ▶️ Run the command\n",
    "!{yolo_cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b844e85d-7b57-46e7-9d98-76e6edd32282",
   "metadata": {},
   "source": [
    "# 5) Locate trained model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
